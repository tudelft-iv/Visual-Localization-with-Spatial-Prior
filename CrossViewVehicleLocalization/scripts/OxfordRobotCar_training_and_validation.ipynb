{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import os\n",
    "os.environ['CUDA_DEVICE_ORDER'] = 'PCI_BUS_ID'\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = \"0\"\n",
    "import numpy as np\n",
    "from spatial_net import *\n",
    "import tensorflow as tf\n",
    "from tensorflow.python.ops.gen_math_ops import *\n",
    "from tf_dropblock.nets.dropblock import DropBlock2D\n",
    "from readdata import InputData\n",
    "from evaluation import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "network_type = \"SAFA_8\"\n",
    "start_epoch = 0\n",
    "batch_size = 64\n",
    "is_training = True\n",
    "number_of_epoch = 1000\n",
    "learning_rate_val = 5e-5\n",
    "keep_prob_val = 0.8\n",
    "keep_prob_dropblock_val = 0.8\n",
    "\n",
    "# -------------------------------------------------------- #\n",
    "\n",
    "def train(start_epoch=0, radius=50):\n",
    "    '''\n",
    "    Train the network and do the test\n",
    "    :param start_epoch: the epoch id start to train. The first epoch is 0.\n",
    "    '''\n",
    "    # import data\n",
    "    print('radius', radius)\n",
    "    input_data = InputData(radius)\n",
    "\n",
    "    # define placeholders\n",
    "    sat_x = tf.placeholder(tf.float32, [None, 256, 256, 3], name='sat_x')\n",
    "    grd_x = tf.placeholder(tf.float32, [None, 154, 231, 3], name='grd_x')\n",
    "    useful_pair_s2g_op = tf.placeholder(tf.float32, [batch_size, batch_size], name='useful_pair_s2g_op')\n",
    "    useful_pair_g2s_op = tf.placeholder(tf.float32, [batch_size, batch_size], name='useful_pair_g2s_op')\n",
    "    utms_x = tf.placeholder(tf.float32, [None, None], name='utms')\n",
    "    \n",
    "    keep_prob = tf.placeholder(tf.float32)\n",
    "    keep_prob_dropblock = tf.placeholder(tf.float32)\n",
    "    learning_rate = tf.placeholder(tf.float32)\n",
    "    training = tf.placeholder(tf.bool)\n",
    "    \n",
    "    drop_block_sat = DropBlock2D(keep_prob=keep_prob_dropblock, block_size=15)\n",
    "    drop_block_grd = DropBlock2D(keep_prob=keep_prob_dropblock, block_size=15)\n",
    "    sat_x_drop = drop_block_sat(sat_x, training)\n",
    "    grd_x_drop = drop_block_grd(grd_x, training)\n",
    "    \n",
    "    # build model\n",
    "    dimension = int(network_type[-1])\n",
    "    sat_global, grd_global = SAFA(sat_x_drop, grd_x_drop, keep_prob, dimension, is_training)\n",
    "\n",
    "    out_channel = sat_global.get_shape().as_list()[-1]\n",
    "    sat_global_descriptor = np.zeros([input_data.get_full_dataset_size(), out_channel])\n",
    "    grd_global_descriptor = np.zeros([input_data.get_full_dataset_size(), out_channel])\n",
    "    loss = compute_loss(sat_global, grd_global, utms_x, input_data.sig, useful_pair_s2g_op, useful_pair_g2s_op)\n",
    "    \n",
    "    # set training\n",
    "    global_step = tf.Variable(0, trainable=False)\n",
    "    with tf.name_scope('train'):\n",
    "        train_step = tf.train.AdamOptimizer(learning_rate, 0.9, 0.999).minimize(loss, global_step=global_step)\n",
    "        \n",
    "\n",
    "    saver = tf.train.Saver(tf.global_variables(), max_to_keep=None)\n",
    "    \n",
    "    global_vars = tf.global_variables()\n",
    "   \n",
    "    var_list = []\n",
    "    for var in global_vars:\n",
    "        if 'VGG' in var.op.name and 'Adam' not in var.op.name:\n",
    "            var_list.append(var)\n",
    "\n",
    "    saver_to_restore = tf.train.Saver(var_list)\n",
    "\n",
    "    # run model\n",
    "    print('run model...')\n",
    "    config = tf.ConfigProto(log_device_placement=False, allow_soft_placement=True)\n",
    "    config.gpu_options.allow_growth = True\n",
    "    config.gpu_options.per_process_gpu_memory_fraction = 1\n",
    "    with tf.Session(config=config) as sess:\n",
    "        sess.run(tf.global_variables_initializer())\n",
    "        print('load model...')\n",
    "\n",
    "        if start_epoch == 0:\n",
    "            load_model_path_init = '/local/zxia/checkpoints/safa/Model/Initialize/initial_model.ckpt' # replace the path with your path to the initialization model\n",
    "            variables_to_restore_init = tf.contrib.framework.get_variables_to_restore(exclude=['spatial_grd','spatial_sat'])\n",
    "            init_fn = tf.contrib.framework.assign_from_checkpoint_fn(load_model_path_init, variables_to_restore_init)\n",
    "            init_fn(sess)\n",
    "            print(\"   Model initialized from: %s\" % load_model_path_init)\n",
    "        else:\n",
    "            load_model_path = '/local/zxia/checkpoints/safa/Model/Oxford/' + str(start_epoch - 1) + '/model.ckpt'\n",
    "\n",
    "            saver.restore(sess, load_model_path)\n",
    "\n",
    "            print(\"   Model loaded from: %s\" % load_model_path)\n",
    "        print('load model...FINISHED')\n",
    "\n",
    "        # Train\n",
    "        for epoch in range(start_epoch, number_of_epoch):\n",
    "            iter = 0\n",
    "            while True:\n",
    "                batch_sat, batch_grd, batch_dis, useful_pairs_s2g, useful_pairs_g2s = input_data.next_pair_batch(batch_size)\n",
    "\n",
    "                if batch_sat is None:\n",
    "                    break\n",
    "\n",
    "                global_step_val = tf.train.global_step(sess, global_step)\n",
    "\n",
    "                feed_dict = {sat_x: batch_sat, grd_x: batch_grd ,utms_x: batch_dis, useful_pair_s2g_op: useful_pairs_s2g,\n",
    "                             useful_pair_g2s_op: useful_pairs_g2s,\n",
    "                             learning_rate: learning_rate_val, keep_prob: keep_prob_val,\n",
    "                            training: True, keep_prob_dropblock: keep_prob_dropblock_val}\n",
    "                _, loss_val = sess.run([train_step, loss], feed_dict=feed_dict)\n",
    "                \n",
    "\n",
    "                if iter % 20 == 0:\n",
    "                    print('global %d, epoch %d, iter %d: loss : %.8f ' % (global_step_val, epoch, iter, loss_val))\n",
    "                    \n",
    "                iter += 1\n",
    "\n",
    "#             model_dir = '/local/zxia/checkpoints/safa/Model/Oxford/' + str(epoch) + '/'\n",
    "\n",
    "#             if not os.path.exists(model_dir):\n",
    "#                 os.makedirs(model_dir)\n",
    "#             save_path = saver.save(sess, model_dir + 'model.ckpt')\n",
    "#             print(\"Model saved in file: %s\" % save_path)\n",
    "\n",
    "            # ---------------------- validation ----------------------\n",
    "            if epoch % 10 == 0:\n",
    "                print('validate...')\n",
    "                print('   compute global descriptors')\n",
    "                input_data.reset_scan()\n",
    "\n",
    "                val_i = 0\n",
    "                while True:\n",
    "                    batch_sat, batch_grd, _ = input_data.next_batch_scan(batch_size)\n",
    "                    if batch_sat is None:\n",
    "                        break\n",
    "                    feed_dict = {sat_x: batch_sat, grd_x: batch_grd, keep_prob: 1.0,\n",
    "                                training: False, keep_prob_dropblock: keep_prob_dropblock_val}\n",
    "                    sat_global_val, grd_global_val = \\\n",
    "                        sess.run([sat_global, grd_global], feed_dict=feed_dict)\n",
    "\n",
    "\n",
    "                    sat_global_descriptor[val_i: val_i + sat_global_val.shape[0], :] = sat_global_val\n",
    "                    grd_global_descriptor[val_i: val_i + grd_global_val.shape[0], :] = grd_global_val\n",
    "                    val_i += sat_global_val.shape[0]\n",
    "\n",
    "                grd_global_descriptor_validation = grd_global_descriptor[0:input_data.valNum,:]\n",
    "\n",
    "                print('   compute accuracy')\n",
    "                dist_array = 2 - 2 * np.matmul(sat_global_descriptor, np.transpose(grd_global_descriptor_validation))\n",
    "\n",
    "                val_accuracy_global = validate(dist_array, 1, input_data)\n",
    "                val_accuracy_local = validate_local(dist_array, 1, input_data)\n",
    "                print('epoch',  epoch, 'val global accuracy =', val_accuracy_global * 100.0)\n",
    "                print('epoch',  epoch, 'val local accuracy = ', val_accuracy_local * 100.0)\n",
    "                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "train(0,50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
